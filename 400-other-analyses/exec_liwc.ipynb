{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import gzip\n",
    "os.chdir(\"/Users/clarkbernier/Box Sync/IBM Local/ibm-topic-model/library/liwc_js\")\n",
    "%run jensen_shannon.py\n",
    "docs = []\n",
    "csv.field_size_limit(93000000)\n",
    "#with open(\"../../outputs/exec_set_docs.csv\", 'r') as csvfile: \n",
    "with gzip.open(\"../../outputs/exec_comps_set_docs.gz\", 'r') as csvfile: \n",
    "    csv_file = csv.DictReader(csvfile)\n",
    "    for row in csv_file:\n",
    "        docs.append(row)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "jensen_shannon_distances(documents, doc_segmentation_fnc=lambda x: [x['frm']], \n",
    "                                pre_processed=False,\n",
    "                                liwc_map=False, vocabsize=1000,\n",
    "                                sampling=False, sampsize=1000,\n",
    "                                min_segment_size=100,\n",
    "                                verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"quote_set\", \"responded_set\", \"early_set\", \"exec_set\", \"mgr_set\", \"asia_set\", \"us_set\", \"euro_set\"]\n",
    "just_bigs = {}\n",
    "\n",
    "for idx, msg in enumerate(docs):\n",
    "    key = msg['user']\n",
    "    if key in targets:\n",
    "        just_bigs[key] = msg\n",
    "\n",
    "dists = {}\n",
    "for key in just_bigs.keys():\n",
    "    dists[key] = get_term_count_distribution([just_bigs[key]], vocabsize=vocabsize, liwc_map=liwc_map, pre_processed=pre_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vocabsize=4000\n",
    "sampling=False \n",
    "sampsize=1000\n",
    "verbose=False\n",
    "pre_processed=False\n",
    "liwc_map=True\n",
    "\n",
    "segments2docs = {}\n",
    "doc_segmentation_fnc=lambda x: [x['user']]\n",
    "documents = docs\n",
    "keys = {}\n",
    "\n",
    "for idx, msg in enumerate(documents):\n",
    "    if verbose:\n",
    "        sys.stderr.write('\\r') ; sys.stderr.write('msg %s' % idx) ; sys.stderr.flush()\n",
    "    key = doc_segmentation_fnc(msg)[0]\n",
    "    segments2docs[key] = msg\n",
    "if verbose: sys.stderr.write('\\n')\n",
    "\n",
    "# For each segment, get count distribution over terms:\n",
    "dists = {}\n",
    "for key in segments2docs.keys():\n",
    "    print key\n",
    "    dists[key] = get_term_count_distribution([segments2docs[key]], vocabsize=vocabsize, liwc_map=liwc_map, pre_processed=pre_processed)\n",
    "\n",
    "\n",
    "#return distances\n",
    "\n",
    "# Now measure pairwise distances:\n",
    "# dist_from_exec = {}\n",
    "# for key in dists.keys():\n",
    "#    dist_from_exec[key] = jensen_shannon(dists[key], dists[\"quote_set\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caluculate an Overall Center\n",
    "seg2docs_copy = segments2docs.copy()\n",
    "dud = seg2docs_copy.pop(\"exec_set\")\n",
    "mega_comment = {'text':\" \".join([d['text'] for d in seg2docs_copy.values()])}\n",
    "overall_center = get_term_count_distribution([mega_comment], vocabsize=vocabsize, liwc_map=liwc_map, pre_processed=pre_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032575943585981995\n",
      "0.03180867029412797\n",
      "0.009102367940830431\n",
      "0.04024722742953861\n",
      "0.02946740997116304\n",
      "0.0279816833870955\n",
      "0.02188255978891531\n",
      "0.010813704192912322\n",
      "0.007160448749681352\n",
      "0.035231822515628286\n",
      "0.03262139400059169\n",
      "0.03479237685507478\n",
      "0.11282687019729255\n"
     ]
    }
   ],
   "source": [
    "print(jensen_shannon(dists[\"quote_set\"], overall_center))\n",
    "print(jensen_shannon(overall_center, dists[\"exec_set\"]))\n",
    "print(jensen_shannon(overall_center, dists[\"mgr_set\"]))\n",
    "print(jensen_shannon(dists[\"quote_set\"], dists[\"exec_set\"]))\n",
    "print(jensen_shannon(dists[\"quote_set\"], dists[\"mgr_set\"]))\n",
    "print(jensen_shannon(dists[\"exec_set\"], dists[\"mgr_set\"]))\n",
    "print(jensen_shannon(overall_center, dists[\"asia_set\"]))\n",
    "print(jensen_shannon(overall_center, dists[\"euro_set\"]))\n",
    "print(jensen_shannon(overall_center, dists[\"us_set\"]))\n",
    "print(jensen_shannon(dists[\"quote_set\"], dists[\"asia_set\"]))\n",
    "print(jensen_shannon(dists[\"quote_set\"], dists[\"euro_set\"]))\n",
    "print(jensen_shannon(dists[\"quote_set\"], dists[\"us_set\"]))\n",
    "print(jensen_shannon(dists[\"quote_set\"], dists[\"early_set\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the Overall Center and the other Target Centers\n",
    "\n",
    "targets = [\"quote_set\", \"responded_set\", \"early_set\", \"exec_set\", \"mgr_set\", \"asia_set\", \"us_set\", \"euro_set\"]\n",
    "\n",
    "out_set = {}\n",
    "for key in overall_center:\n",
    "    ret_set = [overall_center[key]]\n",
    "    for target_key in targets:\n",
    "        ret_set.append(dists[target_key].get(key) or 0)\n",
    "    out_set[key] = ret_set\n",
    "with open('../../outputs/liwc_sets/liwc_distributions.csv','wb') as f:    \n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"liwc.cat\",\"overall.dist\"] + targets)\n",
    "    for k,v in out_set.items():\n",
    "       w.writerow([k] + list(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quote_set\n",
      "responded_set\n",
      "early_set\n",
      "exec_set\n",
      "mgr_set\n",
      "asia_set\n",
      "us_set\n",
      "euro_set\n",
      "overall_center\n",
      "comp87\n",
      "comp22\n"
     ]
    }
   ],
   "source": [
    "# Now measure and output the pairwise distances\n",
    "dists[\"overall_center\"] = overall_center\n",
    "targets = [\"quote_set\", \"responded_set\", \"early_set\", \"exec_set\", \"mgr_set\", \"asia_set\", \"us_set\", \"euro_set\", \"overall_center\", \"comp87\", \"comp22\"]\n",
    "\n",
    "dist_set = {}\n",
    "for target_key in targets:\n",
    "    print target_key\n",
    "    for key in dists.keys():\n",
    "        dist_set[key] = jensen_shannon(dists[key], dists[target_key])\n",
    "    fil_nam = '../../outputs/liwc_sets/dists_from_%s.csv' % (target_key) \n",
    "    with open(fil_nam,'wb') as f:    \n",
    "        w = csv.writer(f)\n",
    "        headr = \"dist.from.%s\" % (target_key)\n",
    "        w.writerow([\"user\",\"dist\"])\n",
    "        w.writerows(dist_set.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quote_set\n",
      "early_set\n",
      "{'quote_set': 0.11282687019729255}\n"
     ]
    }
   ],
   "source": [
    "target_key = targets[2]\n",
    "key = dists.keys()[1]\n",
    "print key\n",
    "print target_key\n",
    "dist_set = {}\n",
    "dist_set[key] = jensen_shannon(dists[key], dists[target_key])\n",
    "\n",
    "print dist_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do the execs look like?\n",
    "print(dists[\"exec_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(just_bigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_bigs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(overall_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
